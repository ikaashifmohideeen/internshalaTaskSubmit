{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBb0GOtj81VVZmTCkiLam4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikaashifmohideeen/internshalaTaskSubmit/blob/main/intershala_web_scrapper_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M9jbwO-sJyRc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup \n",
        "bUrl='https://www.amazon.in'\n",
        "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
        "urllist=[]\n",
        "titlelist=[]\n",
        "descriptionlist=[]\n",
        "pricelist=[]\n",
        "ratinglist=[]\n",
        "reviewcountlist=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "272EOPCau1i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2,52):\n",
        "  baseUrl=f'https://www.amazon.in/s?i=luggage&bbn=2917430031&rh=n%3A2917430031&s=popularity-rank&dc&page={i}&pf_rd_i=13714205031&pf_rd_m=A1VBAL9TL5WCBF&pf_rd_p=6397156b-71ab-46c6-bf4d-6f38da49aa4c&pf_rd_r=25QGB0A506WAQBJMGXQT&pf_rd_s=merchandised-search-8&qid=1663837238&ref=sr_pg_{i}' \n",
        "  r=requests.get(baseUrl,headers=headers)\n",
        "  soup1=BeautifulSoup(r.content,'html.parser')\n",
        "  ud=soup1.find_all(\"a\",class_=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\")\n",
        "  # print(bUrl+ut[\"href\"])\n",
        "  # print(ut.get_text())\n",
        "  title=soup1.find_all(\"span\",class_=\"a-size-base-plus a-color-base\")\n",
        "  price=soup1.find_all(\"span\",class_=\"a-price-whole\")\n",
        "  rating=soup1.find_all(\"span\",class_=\"a-icon-alt\")\n",
        "  nreview=soup1.find_all(\"span\",class_=\"a-size-base s-underline-text\")\n",
        "  # print(len(ud),len(title),len(price),len(rating),len(nreview))\n",
        "  arr=[]\n",
        "  arr.append(len(ud))\n",
        "  arr.append(len(title))\n",
        "  arr.append(len(price))\n",
        "  arr.append(len(rating))\n",
        "  arr.append(len(nreview))\n",
        "  low=min(arr)\n",
        "  # print(low)\n",
        "  for i in range(low):\n",
        "    ul=ud[i][\"href\"]\n",
        "    t=title[i].get_text()\n",
        "    descri=ud[i].get_text()\n",
        "    pricee=price[i].get_text()\n",
        "    rate=rating[i].get_text()\n",
        "    reviw=nreview[i].get_text()\n",
        "    # print(t)\n",
        "    urllist.append(bUrl+ul)\n",
        "    titlelist.append(t)\n",
        "    descriptionlist.append(descri)  \n",
        "    pricelist.append(pricee)\n",
        "    ratinglist.append(rate)\n",
        "    reviewcountlist.append(reviw)\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "KUmgf78rnGN-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(urllist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCMT7ULj3JO_",
        "outputId": "8eb22a1b-d4a7-4def-9010-9164c9455f72"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "#  urllist=[]\n",
        "# titlelist=[]\n",
        "# descriptionlist=[]\n",
        "# pricelist=[]\n",
        "# ratinglist=[]\n",
        "# reviewcountlist=[] \n",
        "  \n",
        "# field names \n",
        "fields = ['Url', 'Title', 'Description', 'PriceList','Ratings','No of reiviewa'] \n",
        "  \n",
        "with open('submitTask1', 'w') as f:\n",
        "      \n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "      \n",
        "    write.writerow(fields)\n",
        "    for i in range(len(urllist)):\n",
        "      write.writerows([[urllist[i],titlelist[i],descriptionlist[i],pricelist[i],ratinglist[i],reviewcountlist[i]]])"
      ],
      "metadata": {
        "id": "oSWKdWB12-pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "task2\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "e89UFONn7vLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rowval=[]\n",
        "nameval=[]\n",
        "t2url=[]\n",
        "lt=0\n",
        "print(urllist[10])"
      ],
      "metadata": {
        "id": "x7dUKV7cJxDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(350):\n",
        "  baseUrl=urllist[i]\n",
        "  r=requests.get(baseUrl,headers=headers)\n",
        "  task2=BeautifulSoup(r.content,'html.parser')\n",
        "  ud=task2.find(\"div\",id=\"detailBullets_feature_div\")\n",
        "  try:\n",
        "    mystr = ud.get_text().split(sep='\\n') \n",
        "    myList = list(filter(('                                    \\u200f').__ne__, mystr))\n",
        "    myList = list(filter(('                                    \\u200e').__ne__, myList))\n",
        "    myList = list(filter(('                                        :').__ne__, myList))\n",
        "    myList = list(filter((\"',\").__ne__, myList))\n",
        "    x=' '.join(myList)\n",
        "    x=x.split(\"  \")\n",
        "    x=  list(filter(('').__ne__, x))\n",
        "    name=[]\n",
        "    val=[]\n",
        "    for k in range(0,len(x)-2,2):\n",
        "      name.append(x[k])\n",
        "      val.append(x[k+1])\n",
        "    rowval.append(val)\n",
        "    nameval.append(name)\n",
        "    t2url.append(urllist[i])\n",
        "    print(i)\n",
        "  except:\n",
        "    lt=lt+1\n",
        "    print(\"loss\",lt)\n",
        "print(\"loss count\",lt)"
      ],
      "metadata": {
        "id": "7451T3EBKHTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=[' Product Dimensions', ' Date First Available', ' Manufacturer', ' ASIN', ' Item model number', ' Country of Origin', ' Department', ' Manufacturer', ' Packer', ' Importer', ' Item Weight', ' Item Dimensions LxWxH', ' Net Quantity', ' Included Components', ' Generic Name']\n",
        "man=test[2]\n",
        "asn=test[3]\n",
        "proddim=test[0]\n",
        "madein=test[5]\n",
        "\n",
        "rmanufactuer=[]\n",
        "rasin=[]\n",
        "rproddim=[]\n",
        "rmadein=[]\n"
      ],
      "metadata": {
        "id": "tc1FqwHBp5NQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(nameval)):\n",
        "  try:\n",
        "    a=nameval[i].index(man)\n",
        "    rmanufactuer.append(rowval[i][a])\n",
        "  except:\n",
        "    rmanufactuer.append(\"NULL\")\n",
        "    \n",
        "  b=nameval[i].index(asn)\n",
        "  rasin.append(rowval[i][b])\n",
        "  try:\n",
        "    c=nameval[i].index(proddim)\n",
        "    rproddim.append(rowval[i][c])\n",
        "  except:\n",
        "    rproddim.append(\"NULL\")\n",
        "  try:\n",
        "    d=nameval[i].index(madein)\n",
        "    rmadein.append(rowval[i][d])\n",
        "  except:\n",
        "    rmadein.append(\"NULL\")\n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "QaWLuU4ArBxM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(t2url),len(rmadein),len(rproddim),len(rasin),len(rmanufactuer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNjy_vlI4igy",
        "outputId": "f1ad729e-fab8-41ec-ae1c-e178233e4bbf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250 250 250 250 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# man=test[2]\n",
        "# asn=test[3]\n",
        "# proddim=test[0]\n",
        "# madein=test[5]\n",
        "fields = [\"URL\",man, asn, proddim, madein] \n",
        "  \n",
        "with open('submitTask2', 'w') as f:\n",
        "      \n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)\n",
        "      \n",
        "    write.writerow(fields)\n",
        "    for i in range(len(t2url)):\n",
        "      write.writerows([[t2url[i],rasin[i],rmanufactuer[i],rproddim[i],rmadein]])"
      ],
      "metadata": {
        "id": "v8QCfs5vxGMW"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}